{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Fill in a module description here\n",
    "output-file: env.html\n",
    "title: env\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/xrsrke/instructGOOSE/blob/main/instruct_goose/env.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TextEnv\n",
       "\n",
       ">      TextEnv (model:Callable, tokenizer:Callable, observation_input:List[int],\n",
       ">               context_length:int=1024)\n",
       "\n",
       "The main Gymnasium class for implementing Reinforcement Learning Agents environments.\n",
       "\n",
       "The class encapsulates an environment with arbitrary behind-the-scenes dynamics through the :meth:`step` and :meth:`reset` functions.\n",
       "An environment can be partially or fully observed by single agents. For multi-agent environments, see PettingZoo.\n",
       "\n",
       "The main API methods that users of this class need to know are:\n",
       "\n",
       "- :meth:`step` - Updates an environment with actions returning the next agent observation, the reward for taking that actions,\n",
       "  if the environment has terminated or truncated due to the latest action and information from the environment about the step, i.e. metrics, debug info.\n",
       "- :meth:`reset` - Resets the environment to an initial state, required before calling step.\n",
       "  Returns the first agent observation for an episode and information, i.e. metrics, debug info.\n",
       "- :meth:`render` - Renders the environments to help visualise what the agent see, examples modes are \"human\", \"rgb_array\", \"ansi\" for text.\n",
       "- :meth:`close` - Closes the environment, important when external software is used, i.e. pygame for rendering, databases\n",
       "\n",
       "Environments have additional attributes for users to understand the implementation\n",
       "\n",
       "- :attr:`action_space` - The Space object corresponding to valid actions, all valid actions should be contained within the space.\n",
       "- :attr:`observation_space` - The Space object corresponding to valid observations, all valid observations should be contained within the space.\n",
       "- :attr:`reward_range` - A tuple corresponding to the minimum and maximum possible rewards for an agent over an episode.\n",
       "  The default reward range is set to :math:`(-\\infty,+\\infty)`.\n",
       "- :attr:`spec` - An environment spec that contains the information used to initialize the environment from :meth:`gymnasium.make`\n",
       "- :attr:`metadata` - The metadata of the environment, i.e. render modes, render fps\n",
       "- :attr:`np_random` - The random number generator for the environment. This is automatically assigned during\n",
       "  ``super().reset(seed=seed)`` and when assessing ``self.np_random``.\n",
       "\n",
       ".. seealso:: For modifying or extending environments use the :py:class:`gymnasium.Wrapper` class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/xrsrke/instructGOOSE/blob/main/instruct_goose/env.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TextEnv\n",
       "\n",
       ">      TextEnv (model:Callable, tokenizer:Callable, observation_input:List[int],\n",
       ">               context_length:int=1024)\n",
       "\n",
       "The main Gymnasium class for implementing Reinforcement Learning Agents environments.\n",
       "\n",
       "The class encapsulates an environment with arbitrary behind-the-scenes dynamics through the :meth:`step` and :meth:`reset` functions.\n",
       "An environment can be partially or fully observed by single agents. For multi-agent environments, see PettingZoo.\n",
       "\n",
       "The main API methods that users of this class need to know are:\n",
       "\n",
       "- :meth:`step` - Updates an environment with actions returning the next agent observation, the reward for taking that actions,\n",
       "  if the environment has terminated or truncated due to the latest action and information from the environment about the step, i.e. metrics, debug info.\n",
       "- :meth:`reset` - Resets the environment to an initial state, required before calling step.\n",
       "  Returns the first agent observation for an episode and information, i.e. metrics, debug info.\n",
       "- :meth:`render` - Renders the environments to help visualise what the agent see, examples modes are \"human\", \"rgb_array\", \"ansi\" for text.\n",
       "- :meth:`close` - Closes the environment, important when external software is used, i.e. pygame for rendering, databases\n",
       "\n",
       "Environments have additional attributes for users to understand the implementation\n",
       "\n",
       "- :attr:`action_space` - The Space object corresponding to valid actions, all valid actions should be contained within the space.\n",
       "- :attr:`observation_space` - The Space object corresponding to valid observations, all valid observations should be contained within the space.\n",
       "- :attr:`reward_range` - A tuple corresponding to the minimum and maximum possible rewards for an agent over an episode.\n",
       "  The default reward range is set to :math:`(-\\infty,+\\infty)`.\n",
       "- :attr:`spec` - An environment spec that contains the information used to initialize the environment from :meth:`gymnasium.make`\n",
       "- :attr:`metadata` - The metadata of the environment, i.e. render modes, render fps\n",
       "- :attr:`np_random` - The random number generator for the environment. This is automatically assigned during\n",
       "  ``super().reset(seed=seed)`` and when assessing ``self.np_random``.\n",
       "\n",
       ".. seealso:: For modifying or extending environments use the :py:class:`gymnasium.Wrapper` class"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(TextEnv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
