{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "import torch\n",
    "tokenizer = BertTokenizerFast.from_pretrained('mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization')\n",
    "model = EncoderDecoderModel.from_pretrained('mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text):\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    return output\n",
    "\n",
    "    # return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"trlX, by CarperAI, is a distributed training framework inspired by the Transformer Reinforcement Learning library (found here: lvwerra/trl). trlX is designed from the ground up to focus on RLHF at scale, which is a necessary factor in reproducing many of the results observed in the recent RLHF literature [Steinnon et al., 2020; Askell et al., 2021, Ouyang et al., 2022].\\\n",
    "    In particular, trlX abstracts the RL stage of the Fine-Tuning Language Models from Human Preferences process, allowing researchers to focus on the high-level choices that govern the finicky dynamics of reinforcement learning rather than the boilerplate code required to run distributed training. It's designed to be flexible enough to support a wide range of algorithms and currently supports implementations of Proximal Policy Optimization (PPO) and Implicit Language Q-Learning (ILQL).\"\n",
    "output = generate_summary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 75])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"trlX, by CarperAI, is a distributed training framework inspired by the Transformer Reinforcement Learning library (found here: lvwerra/trl). trlX is designed from the ground up to focus on RLHF at scale, which is a necessary factor in reproducing many of the results observed in the recent RLHF literature [Steinnon et al., 2020; Askell et al., 2021, Ouyang et al., 2022].\\\n",
    "    In particular, trlX abstracts the RL stage of the Fine-Tuning Language Models from Human Preferences process, allowing researchers to focus on the high-level choices that govern the finicky dynamics of reinforcement learning rather than the boilerplate code required to run distributed training. It's designed to be flexible enough to support a wide range of algorithms and currently supports implementations of Proximal Policy Optimization (PPO) and Implicit Language Q-Learning (ILQL).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.to(device)\n",
    "attention_mask = inputs.attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel.from_pretrained('mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/education/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 142 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 19817,  2140,  2595,  2003,  2881,  2013,  1996,  2598,  2039,\n",
       "          2000,  3579,  2006,  1054,  2140,  2232,  2546,  2012,  4094,  1012,\n",
       "          2009,  1005,  1055,  2881,  2000,  2022, 12379,  2438,  2000,  2490,\n",
       "          1037,  2898,  2846,  1997, 13792,  1012,  1996,  1054,  2140,  2278,\n",
       "          2754,  1997,  1996,  2986,  1011, 17372,  2653,  4275,  2013,  2529,\n",
       "         18394,  2832,  1012,  2023,  2003,  1037,  4072,  5387,  1999, 16360,\n",
       "         14127, 14194,  2075,  2116,  1997,  1996,  3463,  5159,  1999,  1054,\n",
       "          2140,  2546,  3906,  1012,   102]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.generate(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/education/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 142 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"],\n",
    "    output_hidden_states=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 19817,  2140,  2595,  2003,  2881,  2013,  1996,  2598,  2039,\n",
       "          2000,  3579,  2006,  1054,  2140,  2232,  2546,  2012,  4094,  1012,\n",
       "          2009,  1005,  1055,  2881,  2000,  2022, 12379,  2438,  2000,  2490,\n",
       "          1037,  2898,  2846,  1997, 13792,  1012,  1996,  1054,  2140,  2278,\n",
       "          2754,  1997,  1996,  2986,  1011, 17372,  2653,  4275,  2013,  2529,\n",
       "         18394,  2832,  1012,  2023,  2003,  1037,  4072,  5387,  1999, 16360,\n",
       "         14127, 14194,  2075,  2116,  1997,  1996,  3463,  5159,  1999,  1054,\n",
       "          2140,  2546,  3906,  1012,   102]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have to specify either input_ids or inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mforward(\n",
      "\u001b[1;32m      2\u001b[0m     input_ids\u001b[39m=\u001b[39;49minputs[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n",
      "\u001b[1;32m      3\u001b[0m     attention_mask\u001b[39m=\u001b[39;49minputs[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "\u001b[1;32m      4\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:617\u001b[0m, in \u001b[0;36mEncoderDecoderModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    612\u001b[0m     decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n",
      "\u001b[1;32m    613\u001b[0m         labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n",
      "\u001b[1;32m    614\u001b[0m     )\n",
      "\u001b[1;32m    616\u001b[0m \u001b[39m# Decode\u001b[39;00m\n",
      "\u001b[0;32m--> 617\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n",
      "\u001b[1;32m    618\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n",
      "\u001b[1;32m    619\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n",
      "\u001b[1;32m    620\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n",
      "\u001b[1;32m    621\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n",
      "\u001b[1;32m    622\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n",
      "\u001b[1;32m    623\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n",
      "\u001b[1;32m    624\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n",
      "\u001b[1;32m    625\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n",
      "\u001b[1;32m    626\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n",
      "\u001b[1;32m    627\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n",
      "\u001b[1;32m    628\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_decoder,\n",
      "\u001b[1;32m    629\u001b[0m )\n",
      "\u001b[1;32m    631\u001b[0m \u001b[39m# Compute loss independent from decoder (as some shift the logits inside them)\u001b[39;00m\n",
      "\u001b[1;32m    632\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1237\u001b[0m, in \u001b[0;36mBertLMHeadModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[1;32m   1234\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m   1235\u001b[0m     use_cache \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;32m-> 1237\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n",
      "\u001b[1;32m   1238\u001b[0m     input_ids,\n",
      "\u001b[1;32m   1239\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n",
      "\u001b[1;32m   1240\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n",
      "\u001b[1;32m   1241\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n",
      "\u001b[1;32m   1242\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n",
      "\u001b[1;32m   1243\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n",
      "\u001b[1;32m   1244\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n",
      "\u001b[1;32m   1245\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n",
      "\u001b[1;32m   1246\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n",
      "\u001b[1;32m   1247\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n",
      "\u001b[1;32m   1248\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n",
      "\u001b[1;32m   1249\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n",
      "\u001b[1;32m   1250\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n",
      "\u001b[1;32m   1251\u001b[0m )\n",
      "\u001b[1;32m   1253\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m   1254\u001b[0m prediction_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls(sequence_output)\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:973\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[1;32m    971\u001b[0m     input_shape \u001b[39m=\u001b[39m inputs_embeds\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;32m    972\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 973\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m    975\u001b[0m batch_size, seq_length \u001b[39m=\u001b[39m input_shape\n",
      "\u001b[1;32m    976\u001b[0m device \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mdevice \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m inputs_embeds\u001b[39m.\u001b[39mdevice\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either input_ids or inputs_embeds"
     ]
    }
   ],
   "source": [
    "model.forward(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized configuration class <class 'transformers.models.encoder_decoder.configuration_encoder_decoder.EncoderDecoderConfig'> for this kind of AutoModel: AutoModel.\nModel type should be one of AlbertConfig, ASTConfig, BartConfig, BeitConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, CanineConfig, ChineseCLIPConfig, CLIPConfig, CLIPSegConfig, CodeGenConfig, ConditionalDetrConfig, ConvBertConfig, ConvNextConfig, CTRLConfig, CvtConfig, Data2VecAudioConfig, Data2VecTextConfig, Data2VecVisionConfig, DebertaConfig, DebertaV2Config, DecisionTransformerConfig, DeformableDetrConfig, DeiTConfig, DetrConfig, DinatConfig, DistilBertConfig, DonutSwinConfig, DPRConfig, DPTConfig, ElectraConfig, ErnieConfig, EsmConfig, FlaubertConfig, FlavaConfig, FNetConfig, FSMTConfig, FunnelConfig, GLPNConfig, GPT2Config, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GroupViTConfig, HubertConfig, IBertConfig, ImageGPTConfig, JukeboxConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LevitConfig, LiltConfig, LongformerConfig, LongT5Config, LukeConfig, LxmertConfig, M2M100Config, MarianConfig, MarkupLMConfig, MaskFormerConfig, MaskFormerSwinConfig, MBartConfig, MCTCTConfig, MegatronBertConfig, MobileBertConfig, MobileNetV1Config, MobileNetV2Config, MobileViTConfig, MPNetConfig, MT5Config, MvpConfig, NatConfig, NezhaConfig, NystromformerConfig, OpenAIGPTConfig, OPTConfig, OwlViTConfig, PegasusConfig, PegasusXConfig, PerceiverConfig, PLBartConfig, PoolFormerConfig, ProphetNetConfig, QDQBertConfig, ReformerConfig, RegNetConfig, RemBertConfig, ResNetConfig, RetriBertConfig, RobertaConfig, RoCBertConfig, RoFormerConfig, SegformerConfig, SEWConfig, SEWDConfig, Speech2TextConfig, SplinterConfig, SqueezeBertConfig, SwinConfig, Swinv2Config, SwitchTransformersConfig, T5Config, TableTransformerConfig, TapasConfig, TimeSeriesTransformerConfig, TrajectoryTransformerConfig, TransfoXLConfig, UniSpeechConfig, UniSpeechSatConfig, VanConfig, VideoMAEConfig, ViltConfig, VisionTextDualEncoderConfig, VisualBertConfig, ViTConfig, ViTMAEConfig, ViTMSNConfig, Wav2Vec2Config, Wav2Vec2ConformerConfig, WavLMConfig, WhisperConfig, XCLIPConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, YolosConfig, YosoConfig.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39mmrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:466\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    462\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n",
      "\u001b[1;32m    463\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n",
      "\u001b[1;32m    464\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n",
      "\u001b[1;32m    465\u001b[0m     )\n",
      "\u001b[0;32m--> 466\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    467\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    468\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    469\u001b[0m )\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.encoder_decoder.configuration_encoder_decoder.EncoderDecoderConfig'> for this kind of AutoModel: AutoModel.\n",
      "Model type should be one of AlbertConfig, ASTConfig, BartConfig, BeitConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, CanineConfig, ChineseCLIPConfig, CLIPConfig, CLIPSegConfig, CodeGenConfig, ConditionalDetrConfig, ConvBertConfig, ConvNextConfig, CTRLConfig, CvtConfig, Data2VecAudioConfig, Data2VecTextConfig, Data2VecVisionConfig, DebertaConfig, DebertaV2Config, DecisionTransformerConfig, DeformableDetrConfig, DeiTConfig, DetrConfig, DinatConfig, DistilBertConfig, DonutSwinConfig, DPRConfig, DPTConfig, ElectraConfig, ErnieConfig, EsmConfig, FlaubertConfig, FlavaConfig, FNetConfig, FSMTConfig, FunnelConfig, GLPNConfig, GPT2Config, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GroupViTConfig, HubertConfig, IBertConfig, ImageGPTConfig, JukeboxConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LevitConfig, LiltConfig, LongformerConfig, LongT5Config, LukeConfig, LxmertConfig, M2M100Config, MarianConfig, MarkupLMConfig, MaskFormerConfig, MaskFormerSwinConfig, MBartConfig, MCTCTConfig, MegatronBertConfig, MobileBertConfig, MobileNetV1Config, MobileNetV2Config, MobileViTConfig, MPNetConfig, MT5Config, MvpConfig, NatConfig, NezhaConfig, NystromformerConfig, OpenAIGPTConfig, OPTConfig, OwlViTConfig, PegasusConfig, PegasusXConfig, PerceiverConfig, PLBartConfig, PoolFormerConfig, ProphetNetConfig, QDQBertConfig, ReformerConfig, RegNetConfig, RemBertConfig, ResNetConfig, RetriBertConfig, RobertaConfig, RoCBertConfig, RoFormerConfig, SegformerConfig, SEWConfig, SEWDConfig, Speech2TextConfig, SplinterConfig, SqueezeBertConfig, SwinConfig, Swinv2Config, SwitchTransformersConfig, T5Config, TableTransformerConfig, TapasConfig, TimeSeriesTransformerConfig, TrajectoryTransformerConfig, TransfoXLConfig, UniSpeechConfig, UniSpeechSatConfig, VanConfig, VideoMAEConfig, ViltConfig, VisionTextDualEncoderConfig, VisualBertConfig, ViTConfig, ViTMAEConfig, ViTMSNConfig, Wav2Vec2Config, Wav2Vec2ConformerConfig, WavLMConfig, WhisperConfig, XCLIPConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, YolosConfig, YosoConfig."
     ]
    }
   ],
   "source": [
    "model = EncoderDecoderModel.from_pretrained('mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/education/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1177: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead\n",
    "model = AutoModelWithLMHead.from_pretrained(\"HUPD/hupd-t5-small\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"trlX, by CarperAI, is a distributed training framework inspired by the Transformer Reinforcement Learning library (found here: lvwerra/trl). trlX is designed from the ground up to focus on RLHF at scale, which is a necessary factor in reproducing many of the results observed in the recent RLHF literature [Steinnon et al., 2020; Askell et al., 2021, Ouyang et al., 2022].\\\n",
    "    In particular, trlX abstracts the RL stage of the Fine-Tuning Language Models from Human Preferences process, allowing researchers to focus on the high-level choices that govern the finicky dynamics of reinforcement learning rather than the boilerplate code required to run distributed training. It's designed to be flexible enough to support a wide range of algorithms and currently supports implementations of Proximal Policy Optimization (PPO) and Implicit Language Q-Learning (ILQL).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.98k/1.98k [00:00<00:00, 1.95MB/s]\n",
      "Downloading: 100%|██████████| 792k/792k [00:01<00:00, 720kB/s]  \n",
      "Downloading: 100%|██████████| 1.46M/1.46M [00:01<00:00, 1.10MB/s]\n",
      "Downloading: 100%|██████████| 9.59k/9.59k [00:00<00:00, 4.06MB/s]\n",
      "Downloading: 100%|██████████| 1.81k/1.81k [00:00<00:00, 1.35MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "# cuda/cpu\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HUPD/hupd-t5-small\")\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "\u001b[0;32m----> 2\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs\u001b[39m.\u001b[39;49minput_ids)\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1648\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[1;32m   1645\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n",
      "\u001b[1;32m   1647\u001b[0m \u001b[39m# Decode\u001b[39;00m\n",
      "\u001b[0;32m-> 1648\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n",
      "\u001b[1;32m   1649\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n",
      "\u001b[1;32m   1650\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n",
      "\u001b[1;32m   1651\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n",
      "\u001b[1;32m   1652\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n",
      "\u001b[1;32m   1653\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n",
      "\u001b[1;32m   1654\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n",
      "\u001b[1;32m   1655\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n",
      "\u001b[1;32m   1656\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n",
      "\u001b[1;32m   1657\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n",
      "\u001b[1;32m   1658\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n",
      "\u001b[1;32m   1659\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n",
      "\u001b[1;32m   1660\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n",
      "\u001b[1;32m   1661\u001b[0m )\n",
      "\u001b[1;32m   1663\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m   1665\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:937\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[1;32m    935\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m    936\u001b[0m     err_msg_prefix \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdecoder_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m--> 937\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou have to specify either \u001b[39m\u001b[39m{\u001b[39;00merr_msg_prefix\u001b[39m}\u001b[39;00m\u001b[39minput_ids or \u001b[39m\u001b[39m{\u001b[39;00merr_msg_prefix\u001b[39m}\u001b[39;00m\u001b[39minputs_embeds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m    939\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m    940\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model.generate(inputs.input_ids, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    71,  8308,   761,  4732,  3555,    57,     8, 31220, 14317,\n",
       "         10880,   297,  6630,  3595,    41, 19732,   270,    10,     3,    40,\n",
       "           208,   210, 16841,    87,    17,    52,    40,   137,     3,    17,\n",
       "            52,    40,     4,     6,    57,  1184,   883,  9822,     6,    19,\n",
       "             3,     9,  8308,   761,  4732,  3555,    57,     8, 31220, 14317,\n",
       "         10880,   297,  6630,  3595,    41, 19732,   270,    10,     3,    40,\n",
       "           208,   210, 16841,    87,    17,    52,    40,   137,     3,    17,\n",
       "            52,    40,     4,    19,   876,    45,     8,  1591,    95,    12,\n",
       "           992,    30,     3, 12831, 17097,    44,  2643,     6,    84,    19,\n",
       "             3,     9,  1316,  2945,    16, 29103,    53,   186,    13,     8,\n",
       "           772,  6970,    16,     8,  1100,     3, 12831, 17097,  6678,   784,\n",
       "         14337,    77,    29,   106,     3,    15,    17,   491,     5,     6,\n",
       "          6503,   117,  8366,  3820,     3,    15,    17,   491,     1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, CodeGenConfig, CTRLConfig, Data2VecTextConfig, ElectraConfig, ErnieConfig, GPT2Config, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, MarianConfig, MBartConfig, MegatronBertConfig, MvpConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, ReformerConfig, RemBertConfig, RobertaConfig, RoCBertConfig, RoFormerConfig, Speech2Text2Config, TransfoXLConfig, TrOCRConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForCausalLM\n",
      "\u001b[0;32m----> 2\u001b[0m _model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mHUPD/hupd-t5-small\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n",
      "\n",
      "File \u001b[0;32m~/DATA/projects/ai/RLHF/instructGOOSE/env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:466\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    462\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n",
      "\u001b[1;32m    463\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n",
      "\u001b[1;32m    464\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n",
      "\u001b[1;32m    465\u001b[0m     )\n",
      "\u001b[0;32m--> 466\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    467\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    468\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    469\u001b[0m )\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForCausalLM.\n",
      "Model type should be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, CodeGenConfig, CTRLConfig, Data2VecTextConfig, ElectraConfig, ErnieConfig, GPT2Config, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, MarianConfig, MBartConfig, MegatronBertConfig, MvpConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, ReformerConfig, RemBertConfig, RobertaConfig, RoCBertConfig, RoFormerConfig, Speech2Text2Config, TransfoXLConfig, TrOCRConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "_model = AutoModelForCausalLM.from_pretrained(\"HUPD/hupd-t5-small\").to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f90fd3d87d45ed001cb098ecf86280ef7cabc5a3eba02c8102ea8248767e065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
